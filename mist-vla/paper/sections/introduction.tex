\section{Introduction}
Reliable robot behavior in deployment requires both task competence and rapid safety adaptation under distribution shift. Foundation-scale policies can be powerful but brittle in closed-loop manipulation, while heavier planning baselines can introduce latency and model dependence. This paper studies a focused question:

\begin{quote}
\emph{Can a lightweight hidden-state controller predict impending failure and apply continuous corrective steering at inference-time across heterogeneous policy classes?}
\end{quote}

\paragraph{Core idea.}
Attach a compact safety head to frozen policies. Hidden state in; risk, timing, and correction out. No base-policy retraining required.

\paragraph{Why this matters.}
If successful, the method provides a model-agnostic safety layer that can be reused across policy families and embodiments, reducing per-model safety engineering cost.

\paragraph{Target claims for final CoRL submission.}
\begin{itemize}[leftmargin=1.2em]
    \item \textbf{C1:} Failure detection from hidden states transfers beyond training tasks.
    \item \textbf{C2:} Detection-only intervention (freeze/stop) is insufficient for task recovery.
    \item \textbf{C3:} Continuous latent steering improves recovery relative to vanilla and is competitive with planning baselines.
    \item \textbf{C4:} Inference-time steering has favorable control-step latency.
\end{itemize}

\paragraph{What this draft contains now.}
This draft is structured as a complete CoRL paper with all methods and experiment design finalized, and explicit placeholders for final numerical outcomes from ongoing runs.

\paragraph{Embodied extension in scope.}
Beyond simulation, this project now includes an embodied evaluation track on a Yahboom robotic arm platform. The manuscript includes dedicated placeholders for hardware protocol, safety checks, and real-robot outcome reporting so that camera-ready claims remain evidence-linked.
