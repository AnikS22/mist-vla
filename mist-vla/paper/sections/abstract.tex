\begin{abstract}
We present an inference-time latent safety steering framework for robotic policies, targeting both Vision-Language-Action (VLA) foundation models and imitation-learning policies under a shared control interface. Our method predicts three signals from hidden states only: failure risk, time-to-failure, and Cartesian correction vectors. The controller then applies gated, clamped action-space corrections online without retraining the base policy.

We evaluate this framework across in-distribution, strict zero-shot task split, and out-of-distribution obstacle settings, with baselines spanning vanilla execution, stop-only safety intervention, smoothing, random perturbation controls, and MPPI-style planning. The final paper will report full multi-seed results, confidence intervals, and cross-model paired comparisons. Early analyses suggest a consistent compute-latency advantage for latent steering and a strong separation between failure detection alone versus continuous recovery, motivating the proposed approach as a practical safety adapter.

\textbf{Placeholders for camera-ready:} TODO: final aggregate success rates], TODO: final cross-model deltas], TODO: final confidence intervals], TODO: finalized OOD leaderboard].
\end{abstract}
